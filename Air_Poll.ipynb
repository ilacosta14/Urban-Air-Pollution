{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Air Pollution Challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Train data\n",
    "df_train=pd.read_csv('data/Train.csv')\n",
    "\n",
    "# Upload Test data\n",
    "df_test=pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing to drop the Place_ID X Date, as it doesn't contain any additional information\n",
    "df_train = df_train.drop('Place_ID X Date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate columns in target values, 'id' and numerical features\n",
    "target_vars = ['target', 'target_min', 'target_max', 'target_variance', 'target_count']\n",
    "id_cols = ['Place_ID', 'Date']\n",
    "num_cols = [col for col in df_train.columns if col not in target_vars + id_cols and pd.api.types.is_numeric_dtype(df_train[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(target_vars, axis=1)\n",
    "Y = df_train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of nans for each column\n",
    "missing = pd.DataFrame(X_train.isnull().sum(), columns=[\"Amount\"])\n",
    "missing['Percentage'] = round((missing['Amount']/X_train.shape[0])*100, 2)\n",
    "missing[missing['Amount'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing data heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "missing_data = X_train.isnull()\n",
    "sns.heatmap(missing_data, yticklabels=False, cbar=True, cmap='viridis')\n",
    "plt.title('Heatmap for check of missing data\\n(Yellow = Missing, Dark = Present)', fontsize=14)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Observations')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all columns with more than 50% of missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns[X_train.isna().mean() > 0.5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = cols)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For imputing, we consider the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in X_train.columns if col not in id_cols and pd.api.types.is_numeric_dtype(X_train[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute the missing values using the mean per Place_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values per Place_ID using the group mean\n",
    "X_imputed = X_train.copy()\n",
    "X_imputed[num_cols] = X_train.groupby('Place_ID')[num_cols].transform(lambda x: x.fillna(x.mean()))\n",
    "# Fill any remaining NaNs (if an entire group was missing for a feature)\n",
    "# X_train_imputed = X_train_imputed.fillna(X_train_imputed.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the missing values again, as there could still be some extra missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L3_SO2_SO2_column_number_density</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_SO2_column_number_density_amf</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_SO2_slant_column_number_density</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_absorbing_aerosol_index</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_cloud_fraction</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_sensor_azimuth_angle</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_sensor_zenith_angle</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_solar_azimuth_angle</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_SO2_solar_zenith_angle</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Amount  Percentage\n",
       "L3_SO2_SO2_column_number_density             2        0.01\n",
       "L3_SO2_SO2_column_number_density_amf         2        0.01\n",
       "L3_SO2_SO2_slant_column_number_density       2        0.01\n",
       "L3_SO2_absorbing_aerosol_index               2        0.01\n",
       "L3_SO2_cloud_fraction                        2        0.01\n",
       "L3_SO2_sensor_azimuth_angle                  2        0.01\n",
       "L3_SO2_sensor_zenith_angle                   2        0.01\n",
       "L3_SO2_solar_azimuth_angle                   2        0.01\n",
       "L3_SO2_solar_zenith_angle                    2        0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.DataFrame(X_imputed.isnull().sum(), columns=[\"Amount\"])\n",
    "missing['Percentage'] = round((missing['Amount']/X_imputed.shape[0])*100, 2)\n",
    "missing[missing['Amount'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class to impute with mean by Place_ID\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# class GroupByPlaceIDImputer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, place_id='Place_ID', strategy='mean'):\n",
    "#         self.place_id = place_id\n",
    "#         self.strategy = strategy\n",
    "#     def fit(self, X, y=None):\n",
    "#         self.group_mean_ = X.groupby(self.place_id).transform(self.strategy)\n",
    "#         return self\n",
    "#     def transform(self, X):\n",
    "#         X_filled = X.copy()\n",
    "#         for col in X.columns:\n",
    "#             if col != self.place_id:\n",
    "#                 mask = X_filled[col].isna()\n",
    "#                 X_filled.loc[mask, col] = self.group_mean_.loc[mask, col]\n",
    "#         return X_filled.drop(columns=[self.place_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a preprocessing pipeline to impute all the missing NaNs and to scale all the data with a standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # its optional to keep it as we already filled the missing values but its a safety layer for the future unseen data\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# Pipeline([\n",
    "#     ('groupby_imputer', GroupByPlaceIDImputer(place_id='Place_ID', strategy='mean')),\n",
    "#     ('simple_imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('std_scaler', StandardScaler())\n",
    "# ])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', pipeline, num_cols),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = pd.DataFrame(preprocessor.fit_transform(X_train),columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24445 entries, 0 to 24444\n",
      "Data columns (total 69 columns):\n",
      " #   Column                                               Non-Null Count  Dtype \n",
      "---  ------                                               --------------  ----- \n",
      " 0   Date                                                 24445 non-null  object\n",
      " 1   Place_ID                                             24445 non-null  object\n",
      " 2   precipitable_water_entire_atmosphere                 24445 non-null  object\n",
      " 3   relative_humidity_2m_above_ground                    24445 non-null  object\n",
      " 4   specific_humidity_2m_above_ground                    24445 non-null  object\n",
      " 5   temperature_2m_above_ground                          24445 non-null  object\n",
      " 6   u_component_of_wind_10m_above_ground                 24445 non-null  object\n",
      " 7   v_component_of_wind_10m_above_ground                 24445 non-null  object\n",
      " 8   L3_NO2_NO2_column_number_density                     24445 non-null  object\n",
      " 9   L3_NO2_NO2_slant_column_number_density               24445 non-null  object\n",
      " 10  L3_NO2_absorbing_aerosol_index                       24445 non-null  object\n",
      " 11  L3_NO2_cloud_fraction                                24445 non-null  object\n",
      " 12  L3_NO2_sensor_altitude                               24445 non-null  object\n",
      " 13  L3_NO2_sensor_azimuth_angle                          24445 non-null  object\n",
      " 14  L3_NO2_sensor_zenith_angle                           24445 non-null  object\n",
      " 15  L3_NO2_solar_azimuth_angle                           24445 non-null  object\n",
      " 16  L3_NO2_solar_zenith_angle                            24445 non-null  object\n",
      " 17  L3_NO2_stratospheric_NO2_column_number_density       24445 non-null  object\n",
      " 18  L3_NO2_tropopause_pressure                           24445 non-null  object\n",
      " 19  L3_NO2_tropospheric_NO2_column_number_density        24445 non-null  object\n",
      " 20  L3_O3_O3_column_number_density                       24445 non-null  object\n",
      " 21  L3_O3_O3_effective_temperature                       24445 non-null  object\n",
      " 22  L3_O3_cloud_fraction                                 24445 non-null  object\n",
      " 23  L3_O3_sensor_azimuth_angle                           24445 non-null  object\n",
      " 24  L3_O3_sensor_zenith_angle                            24445 non-null  object\n",
      " 25  L3_O3_solar_azimuth_angle                            24445 non-null  object\n",
      " 26  L3_O3_solar_zenith_angle                             24445 non-null  object\n",
      " 27  L3_CO_CO_column_number_density                       24445 non-null  object\n",
      " 28  L3_CO_H2O_column_number_density                      24445 non-null  object\n",
      " 29  L3_CO_cloud_height                                   24445 non-null  object\n",
      " 30  L3_CO_sensor_altitude                                24445 non-null  object\n",
      " 31  L3_CO_sensor_azimuth_angle                           24445 non-null  object\n",
      " 32  L3_CO_sensor_zenith_angle                            24445 non-null  object\n",
      " 33  L3_CO_solar_azimuth_angle                            24445 non-null  object\n",
      " 34  L3_CO_solar_zenith_angle                             24445 non-null  object\n",
      " 35  L3_HCHO_HCHO_slant_column_number_density             24445 non-null  object\n",
      " 36  L3_HCHO_cloud_fraction                               24445 non-null  object\n",
      " 37  L3_HCHO_sensor_azimuth_angle                         24445 non-null  object\n",
      " 38  L3_HCHO_sensor_zenith_angle                          24445 non-null  object\n",
      " 39  L3_HCHO_solar_azimuth_angle                          24445 non-null  object\n",
      " 40  L3_HCHO_solar_zenith_angle                           24445 non-null  object\n",
      " 41  L3_HCHO_tropospheric_HCHO_column_number_density      24445 non-null  object\n",
      " 42  L3_HCHO_tropospheric_HCHO_column_number_density_amf  24445 non-null  object\n",
      " 43  L3_CLOUD_cloud_base_height                           24445 non-null  object\n",
      " 44  L3_CLOUD_cloud_base_pressure                         24445 non-null  object\n",
      " 45  L3_CLOUD_cloud_fraction                              24445 non-null  object\n",
      " 46  L3_CLOUD_cloud_optical_depth                         24445 non-null  object\n",
      " 47  L3_CLOUD_cloud_top_height                            24445 non-null  object\n",
      " 48  L3_CLOUD_cloud_top_pressure                          24445 non-null  object\n",
      " 49  L3_CLOUD_sensor_azimuth_angle                        24445 non-null  object\n",
      " 50  L3_CLOUD_sensor_zenith_angle                         24445 non-null  object\n",
      " 51  L3_CLOUD_solar_azimuth_angle                         24445 non-null  object\n",
      " 52  L3_CLOUD_solar_zenith_angle                          24445 non-null  object\n",
      " 53  L3_CLOUD_surface_albedo                              24445 non-null  object\n",
      " 54  L3_AER_AI_absorbing_aerosol_index                    24445 non-null  object\n",
      " 55  L3_AER_AI_sensor_altitude                            24445 non-null  object\n",
      " 56  L3_AER_AI_sensor_azimuth_angle                       24445 non-null  object\n",
      " 57  L3_AER_AI_sensor_zenith_angle                        24445 non-null  object\n",
      " 58  L3_AER_AI_solar_azimuth_angle                        24445 non-null  object\n",
      " 59  L3_AER_AI_solar_zenith_angle                         24445 non-null  object\n",
      " 60  L3_SO2_SO2_column_number_density                     24445 non-null  object\n",
      " 61  L3_SO2_SO2_column_number_density_amf                 24445 non-null  object\n",
      " 62  L3_SO2_SO2_slant_column_number_density               24445 non-null  object\n",
      " 63  L3_SO2_absorbing_aerosol_index                       24445 non-null  object\n",
      " 64  L3_SO2_cloud_fraction                                24445 non-null  object\n",
      " 65  L3_SO2_sensor_azimuth_angle                          24445 non-null  object\n",
      " 66  L3_SO2_sensor_zenith_angle                           24445 non-null  object\n",
      " 67  L3_SO2_solar_azimuth_angle                           24445 non-null  object\n",
      " 68  L3_SO2_solar_zenith_angle                            24445 non-null  object\n",
      "dtypes: object(69)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X_preprocessed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                    0\n",
       "Place_ID                                0\n",
       "precipitable_water_entire_atmosphere    0\n",
       "relative_humidity_2m_above_ground       0\n",
       "specific_humidity_2m_above_ground       0\n",
       "                                       ..\n",
       "L3_SO2_cloud_fraction                   0\n",
       "L3_SO2_sensor_azimuth_angle             0\n",
       "L3_SO2_sensor_zenith_angle              0\n",
       "L3_SO2_solar_azimuth_angle              0\n",
       "L3_SO2_solar_zenith_angle               0\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good now! Let's move forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24445, 69)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Place_ID', 'precipitable_water_entire_atmosphere',\n",
       "       'relative_humidity_2m_above_ground',\n",
       "       'specific_humidity_2m_above_ground', 'temperature_2m_above_ground',\n",
       "       'u_component_of_wind_10m_above_ground',\n",
       "       'v_component_of_wind_10m_above_ground',\n",
       "       'L3_NO2_NO2_column_number_density',\n",
       "       'L3_NO2_NO2_slant_column_number_density',\n",
       "       'L3_NO2_absorbing_aerosol_index', 'L3_NO2_cloud_fraction',\n",
       "       'L3_NO2_sensor_altitude', 'L3_NO2_sensor_azimuth_angle',\n",
       "       'L3_NO2_sensor_zenith_angle', 'L3_NO2_solar_azimuth_angle',\n",
       "       'L3_NO2_solar_zenith_angle',\n",
       "       'L3_NO2_stratospheric_NO2_column_number_density',\n",
       "       'L3_NO2_tropopause_pressure',\n",
       "       'L3_NO2_tropospheric_NO2_column_number_density',\n",
       "       'L3_O3_O3_column_number_density', 'L3_O3_O3_effective_temperature',\n",
       "       'L3_O3_cloud_fraction', 'L3_O3_sensor_azimuth_angle',\n",
       "       'L3_O3_sensor_zenith_angle', 'L3_O3_solar_azimuth_angle',\n",
       "       'L3_O3_solar_zenith_angle', 'L3_CO_CO_column_number_density',\n",
       "       'L3_CO_H2O_column_number_density', 'L3_CO_cloud_height',\n",
       "       'L3_CO_sensor_altitude', 'L3_CO_sensor_azimuth_angle',\n",
       "       'L3_CO_sensor_zenith_angle', 'L3_CO_solar_azimuth_angle',\n",
       "       'L3_CO_solar_zenith_angle', 'L3_HCHO_HCHO_slant_column_number_density',\n",
       "       'L3_HCHO_cloud_fraction', 'L3_HCHO_sensor_azimuth_angle',\n",
       "       'L3_HCHO_sensor_zenith_angle', 'L3_HCHO_solar_azimuth_angle',\n",
       "       'L3_HCHO_solar_zenith_angle',\n",
       "       'L3_HCHO_tropospheric_HCHO_column_number_density',\n",
       "       'L3_HCHO_tropospheric_HCHO_column_number_density_amf',\n",
       "       'L3_CLOUD_cloud_base_height', 'L3_CLOUD_cloud_base_pressure',\n",
       "       'L3_CLOUD_cloud_fraction', 'L3_CLOUD_cloud_optical_depth',\n",
       "       'L3_CLOUD_cloud_top_height', 'L3_CLOUD_cloud_top_pressure',\n",
       "       'L3_CLOUD_sensor_azimuth_angle', 'L3_CLOUD_sensor_zenith_angle',\n",
       "       'L3_CLOUD_solar_azimuth_angle', 'L3_CLOUD_solar_zenith_angle',\n",
       "       'L3_CLOUD_surface_albedo', 'L3_AER_AI_absorbing_aerosol_index',\n",
       "       'L3_AER_AI_sensor_altitude', 'L3_AER_AI_sensor_azimuth_angle',\n",
       "       'L3_AER_AI_sensor_zenith_angle', 'L3_AER_AI_solar_azimuth_angle',\n",
       "       'L3_AER_AI_solar_zenith_angle', 'L3_SO2_SO2_column_number_density',\n",
       "       'L3_SO2_SO2_column_number_density_amf',\n",
       "       'L3_SO2_SO2_slant_column_number_density',\n",
       "       'L3_SO2_absorbing_aerosol_index', 'L3_SO2_cloud_fraction',\n",
       "       'L3_SO2_sensor_azimuth_angle', 'L3_SO2_sensor_zenith_angle',\n",
       "       'L3_SO2_solar_azimuth_angle', 'L3_SO2_solar_zenith_angle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between Pollutants and Target (PM2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pollutant columns\n",
    "pollutants = [\n",
    "    'L3_NO2_NO2_column_number_density',\n",
    "    'L3_O3_O3_column_number_density',\n",
    "    'L3_CO_CO_column_number_density',\n",
    "    'L3_CO_H2O_column_number_density',\n",
    "    'L3_SO2_SO2_column_number_density'\n",
    "]\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "# Rename pollutants for better readability\n",
    "# pollutant_names = ['NO₂', 'O₃', 'CO', 'CO-H₂O', 'SO₂'] \n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = X_preprocessed[pollutants].corrwith(y_train).sort_values(ascending=False)\n",
    "print(\"Correlations between pollutants and PM2.5:\")\n",
    "print(correlations)\n",
    "\n",
    "# Correlation Matrix Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = X_preprocessed[pollutants].corr()\n",
    "\n",
    "# Create a mapping for renaming columns and index\n",
    "# column_mapping = dict(zip(pollutants, pollutant_names))\n",
    "# column_mapping[target] = 'PM2.5 Target'\n",
    "\n",
    "# Rename the correlation matrix columns and index\n",
    "# corr_matrix_renamed = corr_matrix.rename(columns=column_mapping, index=column_mapping)\n",
    "\n",
    "# Create a mask for the upper triangle to show only lower triangle (stairs effect)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            fmt='.3f', square=True, linewidths=2, cbar_kws={\"shrink\": 0.8},\n",
    "            vmin=-1, vmax=1, mask=mask)\n",
    "plt.title('Correlation Matrix: Pollutants & PM2.5', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to datetime\n",
    "X_preprocessed['Date'] = pd.to_datetime(X_preprocessed['Date'])\n",
    "X_val['Date'] = pd.to_datetime(X_val['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = X_preprocessed.drop(['Place_ID','Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in order to exemplify how the predict will work, we will save the validation set\n",
    "X_val.to_csv(\"data/X_val.csv\")\n",
    "y_val.to_csv(\"data/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = reg.predict(X_preprocessed)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
